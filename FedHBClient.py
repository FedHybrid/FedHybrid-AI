import torch
import requests
from model import client_update_full, load_diabetes_data
from improved_model import ImprovedEnhancerModel
from aggregation import CommunicationEfficientFedHB
from torch.utils.data import DataLoader
import torch.nn as nn
import os
import numpy as np
import pandas as pd
import time
from ckks import batch_encrypt, batch_decrypt
import argparse
import sys

# device ì„¤ì •
device = torch.device('cpu')  # GPU í™˜ê²½ ë¬¸ì œë¡œ CPU ê°•ì œ ì§€ì •

# í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
import os
CLIENT_ID = os.getenv('CLIENT_ID', 'client_1')  # í™˜ê²½ë³€ìˆ˜ë¡œ í´ë¼ì´ì–¸íŠ¸ ID ì„¤ì • ê°€ëŠ¥

# CKKS íŒŒë¼ë¯¸í„° ì„¤ì • (ckks.pyì™€ ë™ì¼í•˜ê²Œ)
z_q = 1 << 10   # 2^10 = 1,024 (í‰ë¬¸ ì¸ì½”ë”©ìš© ìŠ¤ì¼€ì¼)
rescale_q = z_q  # ë¦¬ìŠ¤ì¼€ì¼ë§ìš© ìŠ¤ì¼€ì¼
N = 4  # ìŠ¬ë¡¯ ìˆ˜
s = np.array([1+0j, 1+0j, 0+0j, 0+0j], dtype=np.complex128)  # ë¹„ë°€í‚¤

SERVER_URL = "http://localhost:8000"
NUM_ROUNDS = 5

def evaluate_local_accuracy(model, data_loader, device):
    model.eval()
    correct = 0
    total = 0
    with torch.no_grad():
        for x, y in data_loader:
            x, y = x.to(device), y.to(device)
            outputs = model(x)
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == y).sum().item()
            total += y.size(0)
    acc = correct / total * 100 if total > 0 else 0.0
    return acc

def download_global_model():
    for attempt in range(5):
        try:
            print(f"ê¸€ë¡œë²Œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹œë„ {attempt + 1}/5...")
            r = requests.get(f"{SERVER_URL}/get_model", timeout=10)
            
            if r.status_code == 200:
                with open("global_model.pth", "wb") as f:
                    f.write(r.content)
                
                # íŒŒì¼ í¬ê¸° í™•ì¸
                file_size = os.path.getsize("global_model.pth")
                print(f"ê¸€ë¡œë²Œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ (íŒŒì¼ í¬ê¸°: {file_size} bytes)")
                
                try:
                    model_data = torch.load("global_model.pth", map_location=device, weights_only=False)
                    
                    # ìƒˆ í˜•ì‹ (ë©”íƒ€ë°ì´í„° í¬í•¨)ì¸ì§€ í™•ì¸
                    if isinstance(model_data, dict) and 'state_dict' in model_data:
                        print(f"ëª¨ë¸ ë©”íƒ€ë°ì´í„°: {model_data.get('model_type', 'Unknown')} v{model_data.get('version', 'Unknown')}")
                        print(f"ì„œë²„ ëª¨ë¸ ì…ë ¥ ì°¨ì›: {model_data.get('input_dim', 'Unknown')}")
                        state_dict = model_data['state_dict']
                    else:
                        # êµ¬ í˜•ì‹ (state_dictë§Œ)
                        print("êµ¬ í˜•ì‹ì˜ ëª¨ë¸ íŒŒì¼ì…ë‹ˆë‹¤.")
                        state_dict = model_data
                    
                    os.remove("global_model.pth")
                    print("ê¸€ë¡œë²Œ ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
                    return state_dict
                except Exception as e:
                    print(f"ê¸€ë¡œë²Œ ëª¨ë¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
                    if os.path.exists("global_model.pth"):
                        os.remove("global_model.pth")
            else:
                print(f"ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {r.status_code} - {r.text}")
                
        except requests.exceptions.ConnectionError:
            print(f"ì„œë²„ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/5)")
        except requests.exceptions.Timeout:
            print(f"ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼ (ì‹œë„ {attempt + 1}/5)")
        except Exception as e:
            print(f"ê¸€ë¡œë²Œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
        
        if attempt < 4:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ëŒ€ê¸°
            print("3ì´ˆ í›„ ì¬ì‹œë„...")
            time.sleep(3)
    
    raise RuntimeError("ê¸€ë¡œë²Œ ëª¨ë¸ì„ ì •ìƒì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")

def analyze_feature_importance(model, data_loader, feature_names, device):
    """íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„"""
    model.eval()
    feature_importance = {}
    
    print("=== íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„ ì‹œì‘ ===")
    
    with torch.no_grad():
        # ì²« ë²ˆì§¸ ë°°ì¹˜ë¡œ íŠ¹ì„± ì¤‘ìš”ë„ ê³„ì‚°
        for x, _ in data_loader:
            x = x.to(device)
            x.requires_grad_(True)
            
            # ì›ë³¸ ì˜ˆì¸¡
            outputs = model(x)
            probs = torch.softmax(outputs, dim=1)
            original_prob = probs[:, 1].mean()  # ë‹¹ë‡¨ë³‘ í™•ë¥ 
            
            # ê° íŠ¹ì„±ë³„ ì¤‘ìš”ë„ ê³„ì‚°
            for i, feature_name in enumerate(feature_names):
                # íŠ¹ì„±ê°’ì„ 0ìœ¼ë¡œ ì„¤ì •
                x_modified = x.clone()
                x_modified[:, i] = 0
                
                # ìˆ˜ì •ëœ ì˜ˆì¸¡
                outputs_modified = model(x_modified)
                probs_modified = torch.softmax(outputs_modified, dim=1)
                modified_prob = probs_modified[:, 1].mean()
                
                # ì¤‘ìš”ë„ = ì›ë³¸ í™•ë¥  - ìˆ˜ì •ëœ í™•ë¥ 
                importance = abs(original_prob - modified_prob).item()
                feature_importance[feature_name] = importance
            
            break  # ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ ì‚¬ìš©
    
    # ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_importance = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
    
    print("íŠ¹ì„± ì¤‘ìš”ë„ (ë†’ì€ ìˆœ):")
    for feature, importance in sorted_importance:
        print(f"  {feature}: {importance:.4f}")
    
    return feature_importance

def explain_prediction(model, sample_data, feature_names, device):
    """ê°œë³„ ì˜ˆì¸¡ì— ëŒ€í•œ ì„¤ëª…"""
    model.eval()
    
    with torch.no_grad():
        x = torch.tensor(sample_data, dtype=torch.float32).unsqueeze(0).to(device)
        outputs = model(x)
        probs = torch.softmax(outputs, dim=1)
        diabetes_prob = probs[0, 1].item()
        
        print(f"\n=== ê°œë³„ ì˜ˆì¸¡ ì„¤ëª… ===")
        print(f"ë‹¹ë‡¨ë³‘ í™•ë¥ : {diabetes_prob:.4f}")
        
        # ê° íŠ¹ì„±ì˜ ê¸°ì—¬ë„ ê³„ì‚°
        contributions = {}
        for i, feature_name in enumerate(feature_names):
            x_modified = x.clone()
            x_modified[0, i] = 0  # íŠ¹ì„±ê°’ì„ 0ìœ¼ë¡œ ì„¤ì •
            
            outputs_modified = model(x_modified)
            probs_modified = torch.softmax(outputs_modified, dim=1)
            modified_prob = probs_modified[0, 1].item()
            
            contribution = diabetes_prob - modified_prob
            contributions[feature_name] = contribution
        
        # ê¸°ì—¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_contributions = sorted(contributions.items(), key=lambda x: abs(x[1]), reverse=True)
        
        print("íŠ¹ì„±ë³„ ê¸°ì—¬ë„:")
        for feature, contribution in sorted_contributions[:5]:  # ìƒìœ„ 5ê°œë§Œ
            direction = "ì¦ê°€" if contribution > 0 else "ê°ì†Œ"
            print(f"  {feature}: {contribution:.4f} ({direction})")
        
        return contributions

def explain_prediction_process(model, sample_data, feature_names, device):
    """ì˜ˆì¸¡ ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ì„¤ëª…"""
    model.eval()
    
    print(f"\n=== ì˜ˆì¸¡ ê³¼ì • ìƒì„¸ ì„¤ëª… ===")
    
    with torch.no_grad():
        x = torch.tensor(sample_data, dtype=torch.float32).unsqueeze(0).to(device)
        
        # 1ë‹¨ê³„: ì…ë ¥ ë°ì´í„° í™•ì¸
        print(f"1ë‹¨ê³„: ì…ë ¥ ë°ì´í„°")
        print(f"  ì…ë ¥ í˜•íƒœ: {x.shape}")
        print(f"  íŠ¹ì„± ê°œìˆ˜: {len(feature_names)}")
        print(f"  ì…ë ¥ê°’ ë²”ìœ„: {x.min().item():.2f} ~ {x.max().item():.2f}")
        
        # 2ë‹¨ê³„: ëª¨ë¸ í†µê³¼
        print(f"\n2ë‹¨ê³„: ëª¨ë¸ í†µê³¼")
        outputs = model(x)
        print(f"  ëª¨ë¸ ì¶œë ¥ (ë¡œì§“): {outputs}")
        print(f"  ì¶œë ¥ í˜•íƒœ: {outputs.shape}")
        
        # 3ë‹¨ê³„: ì†Œí”„íŠ¸ë§¥ìŠ¤ ì ìš©
        probs = torch.softmax(outputs, dim=1)
        print(f"\n3ë‹¨ê³„: ì†Œí”„íŠ¸ë§¥ìŠ¤ ì ìš©")
        print(f"  ì†Œí”„íŠ¸ë§¥ìŠ¤ ê²°ê³¼: {probs}")
        print(f"  í™•ë¥  í•©ê³„: {probs.sum().item():.4f}")
        
        # 4ë‹¨ê³„: ìµœì¢… ì˜ˆì¸¡
        diabetes_prob = probs[0, 1].item()
        normal_prob = probs[0, 0].item()
        predicted_class = torch.argmax(outputs, dim=1).item()
        
        print(f"\n4ë‹¨ê³„: ìµœì¢… ì˜ˆì¸¡")
        print(f"  ì •ìƒ í™•ë¥ : {normal_prob:.4f}")
        print(f"  ë‹¹ë‡¨ë³‘ í™•ë¥ : {diabetes_prob:.4f}")
        print(f"  ì˜ˆì¸¡ í´ë˜ìŠ¤: {predicted_class} ({'ë‹¹ë‡¨ë³‘' if predicted_class == 1 else 'ì •ìƒ'})")
        
        # 5ë‹¨ê³„: íŠ¹ì„±ë³„ ê¸°ì—¬ë„ ë¶„ì„
        print(f"\n5ë‹¨ê³„: íŠ¹ì„±ë³„ ê¸°ì—¬ë„ ë¶„ì„")
        contributions = {}
        for i, feature_name in enumerate(feature_names):
            x_modified = x.clone()
            x_modified[0, i] = 0  # íŠ¹ì„±ê°’ì„ 0ìœ¼ë¡œ ì„¤ì •
            
            outputs_modified = model(x_modified)
            probs_modified = torch.softmax(outputs_modified, dim=1)
            modified_prob = probs_modified[0, 1].item()
            
            contribution = diabetes_prob - modified_prob
            contributions[feature_name] = contribution
            
            print(f"  {feature_name}: {contribution:+.4f} (ì›ë³¸: {diabetes_prob:.4f} â†’ ìˆ˜ì •: {modified_prob:.4f})")
        
        # 6ë‹¨ê³„: í•´ì„
        print(f"\n6ë‹¨ê³„: ì˜ˆì¸¡ í•´ì„")
        if diabetes_prob > 0.5:
            print(f"  â†’ ë‹¹ë‡¨ë³‘ ìœ„í—˜ì´ ë†’ìŒ (í™•ë¥ : {diabetes_prob:.1%})")
        else:
            print(f"  â†’ ì •ìƒ ë²”ìœ„ (ë‹¹ë‡¨ë³‘ í™•ë¥ : {diabetes_prob:.1%})")
        
        # ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±ë“¤
        sorted_contributions = sorted(contributions.items(), key=lambda x: abs(x[1]), reverse=True)
        print(f"  ì£¼ìš” ì˜í–¥ íŠ¹ì„±:")
        for i, (feature, contribution) in enumerate(sorted_contributions[:3]):
            direction = "ì¦ê°€" if contribution > 0 else "ê°ì†Œ"
            print(f"    {i+1}. {feature}: {contribution:+.4f} ({direction})")
        
        return {
            'diabetes_prob': diabetes_prob,
            'predicted_class': predicted_class,
            'contributions': contributions
        }

def predict_diabetes_probability_with_explanation(model, data_loader, feature_names, device):
    """í•´ì„ ê°€ëŠ¥í•œ ë‹¹ë‡¨ë³‘ í™•ë¥  ì˜ˆì¸¡"""
    model.eval()
    probabilities = []
    predictions = []
    explanations = []
    
    print(f"=== í•´ì„ ê°€ëŠ¥í•œ ì˜ˆì¸¡ ì‹œì‘ ===")
    print(f"ëª¨ë¸ ìƒíƒœ: {model.training}")
    print(f"ë””ë°”ì´ìŠ¤: {device}")
    print(f"íŠ¹ì„± ê°œìˆ˜: {len(feature_names)}")
    
    # íŠ¹ì„± ì¤‘ìš”ë„ ë¶„ì„
    feature_importance = analyze_feature_importance(model, data_loader, feature_names, device)
    
    with torch.no_grad():
        for batch_idx, (x, _) in enumerate(data_loader):
            x = x.to(device)
            outputs = model(x)
            
            # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ì¶œë ¥ í™•ì¸
            if batch_idx == 0:
                print(f"\nì²« ë²ˆì§¸ ë°°ì¹˜ ë¶„ì„:")
                print(f"  ì…ë ¥ í˜•íƒœ: {x.shape}")
                print(f"  ëª¨ë¸ ì¶œë ¥ í˜•íƒœ: {outputs.shape}")
                print(f"  ì¶œë ¥ ìƒ˜í”Œ: {outputs[:3]}")
            
            probs = torch.softmax(outputs, dim=1)
            
            # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ í™•ë¥  í™•ì¸
            if batch_idx == 0:
                print(f"  í™•ë¥  í˜•íƒœ: {probs.shape}")
                print(f"  í™•ë¥  ìƒ˜í”Œ: {probs[:3]}")
                print(f"  í™•ë¥  í•©ê³„: {probs.sum(dim=1)[:3]}")
            
            batch_probs = probs[:, 1].cpu().numpy()  # ë‹¹ë‡¨ë³‘ í™•ë¥  (í´ë˜ìŠ¤ 1)
            _, predicted = torch.max(outputs, 1)
            batch_preds = predicted.cpu().numpy()
            
            probabilities.extend(batch_probs)
            predictions.extend(batch_preds)
            
            # ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ì²« ë²ˆì§¸ ìƒ˜í”Œì— ëŒ€í•œ ìƒì„¸ ì„¤ëª…
            if batch_idx == 0:
                print(f"\nì²« ë²ˆì§¸ ìƒ˜í”Œ ìƒì„¸ ë¶„ì„:")
                sample_data = x[0].cpu().numpy()
                sample_explanation = explain_prediction_process(model, sample_data, feature_names, device)
                explanations.append(sample_explanation)
            
            # ë””ë²„ê¹…: ì²« ë²ˆì§¸ ë°°ì¹˜ì˜ ì˜ˆì¸¡ í™•ì¸
            if batch_idx == 0:
                print(f"  ì˜ˆì¸¡: {batch_preds[:3]}")
                print(f"  ë‹¹ë‡¨ë³‘ í™•ë¥ : {batch_probs[:3]}")
    
    probabilities = np.array(probabilities)
    predictions = np.array(predictions)
    
    print(f"\n=== ì „ì²´ ì˜ˆì¸¡ ì™„ë£Œ ===")
    print(f"í™•ë¥  ë²”ìœ„: {probabilities.min():.4f} ~ {probabilities.max():.4f}")
    print(f"í™•ë¥  í‰ê· : {probabilities.mean():.4f}")
    print(f"ì˜ˆì¸¡ ë¶„í¬: {np.bincount(predictions)}")
    print(f"ê³ ìœ  í™•ë¥  ê°’ ê°œìˆ˜: {len(np.unique(probabilities))}")
    
    return probabilities, predictions, feature_importance

def save_results_to_excel(original_data, probabilities, predictions, feature_importance=None, output_path='prediction_results.xlsx'):
    """ê²°ê³¼ë¥¼ ì—‘ì…€ íŒŒì¼ë¡œ ì €ì¥ (ê°„ì†Œí™” ë²„ì „)"""
    try:
        print(f"ê²°ê³¼ ì €ì¥ ì‹œì‘: {len(probabilities)}ê°œ ë°ì´í„°", flush=True)
        
        # NaN ê°’ ì²˜ë¦¬
        probabilities = np.nan_to_num(probabilities, nan=0.0, posinf=1.0, neginf=0.0)
        predictions = np.nan_to_num(predictions, nan=0, posinf=1, neginf=0).astype(int)
        
        # ë°ì´í„° í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ë° ì‹œê°„ ì ˆì•½)
        max_rows = 10000  # ìµœëŒ€ 10,000í–‰ìœ¼ë¡œ ì œí•œ
        if len(original_data) > max_rows:
            print(f"ë°ì´í„° í¬ê¸°ê°€ í½ë‹ˆë‹¤. ìƒìœ„ {max_rows}ê°œ í–‰ë§Œ ì €ì¥í•©ë‹ˆë‹¤.", flush=True)
            # í™•ë¥  ê¸°ì¤€ìœ¼ë¡œ ìƒìœ„ ë°ì´í„°ë§Œ ì„ íƒ
            top_indices = np.argsort(probabilities)[-max_rows:]
            original_data = original_data.iloc[top_indices]
            probabilities = probabilities[top_indices]
            predictions = predictions[top_indices]
        
        # ì›ë³¸ ë°ì´í„°ì— ì˜ˆì¸¡ ê²°ê³¼ ì¶”ê°€
        result_df = original_data.copy()
        
        # ë¶ˆí•„ìš”í•œ Unnamed ì»¬ëŸ¼ë“¤ ì œê±° (Unnamed:50, Unnamed:51, Unnamed:52 ë“±)
        unnamed_cols = [col for col in result_df.columns if col.startswith('Unnamed:')]
        if unnamed_cols:
            print(f"ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°: {unnamed_cols}", flush=True)
            result_df = result_df.drop(columns=unnamed_cols)
        
        result_df['ë‹¹ë‡¨ë³‘_í™•ë¥ '] = probabilities
        result_df['ì˜ˆì¸¡_ê²°ê³¼'] = predictions
        result_df['ì˜ˆì¸¡_ë¼ë²¨'] = ['ë‹¹ë‡¨ë³‘' if p == 1 else 'ì •ìƒ' for p in predictions]
        
        # í™•ë¥ ë³„ë¡œ ì •ë ¬
        result_df = result_df.sort_values('ë‹¹ë‡¨ë³‘_í™•ë¥ ', ascending=False)
        
        print(f"ì—‘ì…€ íŒŒì¼ ì €ì¥ ì‹œì‘: {len(result_df)}í–‰", flush=True)
        
        # ê°„ë‹¨í•œ ì—‘ì…€ ì €ì¥ (ì‹œíŠ¸ í•˜ë‚˜ë§Œ)
        try:
            result_df.to_excel(output_path, index=False, engine='openpyxl')
            print(f"ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}", flush=True)
        except Exception as excel_error:
            print(f"ì—‘ì…€ ì €ì¥ ì‹¤íŒ¨, CSVë¡œ ëŒ€ì²´ ì €ì¥: {excel_error}", flush=True)
            csv_path = output_path.replace('.xlsx', '.csv')
            result_df.to_csv(csv_path, index=False)
            print(f"CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {csv_path}", flush=True)
            return True
        
        # ê¸°ë³¸ í†µê³„ ì¶œë ¥
        print(f"ê²°ê³¼ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.", flush=True)
        print(f"ì´ {len(result_df)}ê°œ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ì™„ë£Œ", flush=True)
        print(f"ë‹¹ë‡¨ë³‘ ì˜ˆì¸¡: {sum(predictions)}ê°œ", flush=True)
        print(f"ì •ìƒ ì˜ˆì¸¡: {len(predictions) - sum(predictions)}ê°œ", flush=True)
        print(f"í‰ê·  ë‹¹ë‡¨ë³‘ í™•ë¥ : {np.mean(probabilities):.4f}", flush=True)
        
        if os.path.exists(output_path):
            print(f"íŒŒì¼ í¬ê¸°: {os.path.getsize(output_path)} bytes", flush=True)
        
        return True
        
    except Exception as e:
        print(f"ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

def main(input_file=None):
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=== FedHybrid í´ë¼ì´ì–¸íŠ¸ ì‹œì‘ ===", flush=True)
    
    # ì…ë ¥ íŒŒì¼ ì²˜ë¦¬
    if input_file and os.path.exists(input_file):
        print(f"ì…ë ¥ íŒŒì¼: {input_file}", flush=True)
        data_file = input_file
    else:
        print("ê¸°ë³¸ ë°ì´í„° íŒŒì¼ ì‚¬ìš©: diabetic_data.csv", flush=True)
        data_file = 'diabetic_data.csv'
    
    # ë°ì´í„°ì…‹ ì¤€ë¹„ (ê°œì„ ëœ ë²„ì „ ì‚¬ìš©)
    try:
        from improved_model import load_improved_diabetes_data
        train_dataset, test_dataset, class_weights, selected_features = load_improved_diabetes_data(data_file)
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)
        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)
        input_dim = train_dataset.X.shape[1]
        print(f"ê°œì„ ëœ ë°ì´í„° ë¡œë“œ ì™„ë£Œ - ì…ë ¥ ì°¨ì›: {input_dim}", flush=True)
        print(f"ì„ íƒëœ íŠ¹ì„±: {selected_features}", flush=True)
        print(f"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weights}", flush=True)
    except Exception as e:
        print(f"ê°œì„ ëœ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ ë²„ì „ ì‚¬ìš©: {e}", flush=True)
        try:
            train_dataset, test_dataset = load_diabetes_data(data_file)
            train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)
            test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)
            input_dim = train_dataset.X.shape[1]
            class_weights = None
            selected_features = None
            print(f"ê¸°ë³¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ - ì…ë ¥ ì°¨ì›: {input_dim}", flush=True)
        except Exception as e2:
            print(f"ë°ì´í„° ë¡œë“œ ì™„ì „ ì‹¤íŒ¨: {e2}", flush=True)
            return False

    # ëª¨ë¸ ì¤€ë¹„ (EnhancerModel)
    client_model = ImprovedEnhancerModel(input_dim=input_dim, num_classes=2).to(device)
    global_model = ImprovedEnhancerModel(input_dim=input_dim, num_classes=2).to(device)  # ê¸€ë¡œë²Œ ëª¨ë¸ ì¶”ê°€

    print(f"=== {NUM_ROUNDS}ë¼ìš´ë“œ í•™ìŠµ ì‹œì‘ ===", flush=True)
    
    for r in range(NUM_ROUNDS):
        round_start_time = time.time()  # ë¼ìš´ë“œ ì‹œì‘ ì‹œê°„
        print(f"\nğŸš€ === ë¼ìš´ë“œ {r+1}/{NUM_ROUNDS} ì‹œì‘ ===", flush=True)
        print(f"â° ì‹œì‘ ì‹œê°„: {time.strftime('%H:%M:%S')}", flush=True)
        
        # 1ë‹¨ê³„: ê¸€ë¡œë²Œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
        print(f"ğŸ“¥ 1ë‹¨ê³„: ì„œë²„ì—ì„œ ê¸€ë¡œë²Œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì¤‘...", flush=True)
        try:
            state_dict = download_global_model()
            
            # ì„œë²„ ëª¨ë¸ê³¼ í´ë¼ì´ì–¸íŠ¸ ëª¨ë¸ì˜ ì°¨ì›ì´ ë‹¤ë¥¸ ê²½ìš° ì²˜ë¦¬
            try:
                global_model.load_state_dict(state_dict)
                print(f"âœ… ê¸€ë¡œë²Œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ ì„±ê³µ", flush=True)
            except RuntimeError as e:
                if "size mismatch" in str(e):
                    print(f"âŒ ëª¨ë¸ ì°¨ì› ë¶ˆì¼ì¹˜: {e}", flush=True)
                    print("ğŸ”„ ë¡œì»¬ ëª¨ë¸ ì´ˆê¸°í™”ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.", flush=True)
                    # ê¸€ë¡œë²Œ ëª¨ë¸ì„ í´ë¼ì´ì–¸íŠ¸ ëª¨ë¸ê³¼ ë™ì¼í•˜ê²Œ ì´ˆê¸°í™”
                    global_model.load_state_dict(client_model.state_dict())
                else:
                    raise e
        except Exception as e:
            print(f"âŒ ê¸€ë¡œë²Œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ/ë¡œë“œ ì‹¤íŒ¨: {e}", flush=True)
            print("ğŸ”„ ë¡œì»¬ ëª¨ë¸ ì´ˆê¸°í™”ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.", flush=True)
            # ê¸€ë¡œë²Œ ëª¨ë¸ì„ í´ë¼ì´ì–¸íŠ¸ ëª¨ë¸ê³¼ ë™ì¼í•˜ê²Œ ì´ˆê¸°í™”
            global_model.load_state_dict(client_model.state_dict())
        
        acc_before = evaluate_local_accuracy(client_model, train_loader, device)
        
        # ëª¨ë¸ ìƒíƒœ í™•ì¸ (ë””ë²„ê¹…)
        print(f"í•™ìŠµ ì „ ëª¨ë¸ ìƒíƒœ í™•ì¸:")
        print(f"  - ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in client_model.parameters())}")
        print(f"  - ì²« ë²ˆì§¸ ë ˆì´ì–´ ê°€ì¤‘ì¹˜ ë²”ìœ„: {client_model.feature_extractor[0].weight.min().item():.4f} ~ {client_model.feature_extractor[0].weight.max().item():.4f}")
        
        # 2ë‹¨ê³„: ë¡œì»¬ í•™ìŠµ ìˆ˜í–‰
        print(f"ğŸ“ 2ë‹¨ê³„: ë¡œì»¬ ëª¨ë¸ í•™ìŠµ ì‹œì‘...", flush=True)
        training_start_time = time.time()
        accuracy = 0.0  # ê¸°ë³¸ê°’
        try:
            from improved_model import improved_client_update
            updated_model, avg_loss, epochs, num_samples, accuracy = improved_client_update(
                client_model, global_model, train_loader, nn.CrossEntropyLoss(), r, device, class_weights
            )
            print(f"âœ… ê°œì„ ëœ í•™ìŠµ í•¨ìˆ˜ ì‚¬ìš© ì™„ë£Œ", flush=True)
        except Exception as e:
            print(f"ê°œì„ ëœ í•™ìŠµ ì‹¤íŒ¨, ê¸°ë³¸ ë²„ì „ ì‚¬ìš©: {e}", flush=True)
            result = client_update_full(
                client_model, global_model, train_loader, nn.CrossEntropyLoss(), r, device,
                use_kd=False, use_fedprox=False, use_pruning=False  # ì•ˆì •ì„±ì„ ìœ„í•´ ëª¨ë“  ê³ ê¸‰ ê¸°ëŠ¥ ë¹„í™œì„±í™”
            )
            if len(result) == 4:
                updated_model, avg_loss, epochs, num_samples = result
                accuracy = 0.0  # ê¸°ë³¸ í•¨ìˆ˜ëŠ” ì •í™•ë„ë¥¼ ë°˜í™˜í•˜ì§€ ì•ŠìŒ
            else:
                updated_model, avg_loss, epochs, num_samples, accuracy = result
        training_end_time = time.time()
        training_duration = training_end_time - training_start_time
        acc_after = evaluate_local_accuracy(updated_model, train_loader, device)
        
        # í•™ìŠµ í›„ ëª¨ë¸ ìƒíƒœ í™•ì¸ (ë””ë²„ê¹…)
        print(f"í•™ìŠµ í›„ ëª¨ë¸ ìƒíƒœ í™•ì¸:")
        print(f"  - ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in updated_model.parameters())}")
        print(f"  - ì²« ë²ˆì§¸ ë ˆì´ì–´ ê°€ì¤‘ì¹˜ ë²”ìœ„: {updated_model.feature_extractor[0].weight.min().item():.4f} ~ {updated_model.feature_extractor[0].weight.max().item():.4f}")
        
        # ë¡œì»¬ í•™ìŠµ ì™„ë£Œëœ ëª¨ë¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš© (FedAvg ì›ì¹™)
        print(f"=== ë¡œì»¬ í•™ìŠµ ì™„ë£Œ ===")
        print(f"ë¡œì»¬ í•™ìŠµëœ ëª¨ë¸ íŒŒë¼ë¯¸í„°ë¥¼ ì„œë²„ë¡œ ì „ì†¡í•  ì¤€ë¹„ ì™„ë£Œ")
        
        # í•™ìŠµëœ ëª¨ë¸ì„ í´ë¼ì´ì–¸íŠ¸ ëª¨ë¸ì— ë³µì‚¬
        client_model.load_state_dict(updated_model.state_dict())
        
        # === 3ë‹¨ê³„: í´ë¼ì´ì–¸íŠ¸ ë°ì´í„°ë¥¼ CKKSë¡œ ì•”í˜¸í™” ===
        encryption_start_time = time.time()
        print(f"\nğŸ” 3ë‹¨ê³„: í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° CKKS ì•”í˜¸í™”", flush=True)
        state_dict = client_model.state_dict()
        print(f"ğŸ“¦ ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {len(state_dict)}ê°œ ë ˆì´ì–´", flush=True)
        
        # 1) Tensor â†’ flat numpy vector
        flat = np.concatenate([param.cpu().numpy().flatten() for param in state_dict.values()])
        print(f"í‰ë©´í™”ëœ ë²¡í„° í¬ê¸°: {len(flat)}")
        
        # 2) CKKS ì•”í˜¸í™”
        print(f"ğŸ”’ CKKS ì•”í˜¸í™” ì§„í–‰ ì¤‘...", flush=True)
        c0_list, c1_list = batch_encrypt(flat)
        encrypted_flat = {'c0_list': c0_list, 'c1_list': c1_list}
        encryption_end_time = time.time()
        encryption_duration = encryption_end_time - encryption_start_time
        print(f"âœ… CKKS ì•”í˜¸í™” ì™„ë£Œ (ì†Œìš”ì‹œê°„: {encryption_duration:.2f}ì´ˆ)", flush=True)
        
        # === 4ë‹¨ê³„: ì•”í˜¸í™”ëœ ë°ì´í„°ë¥¼ ì„œë²„ë¡œ ì „ì†¡ ===
        upload_start_time = time.time()
        print(f"\nğŸ“¤ 4ë‹¨ê³„: ì•”í˜¸í™”ëœ ë°ì´í„° ì„œë²„ ì „ì†¡", flush=True)
        
        # NaN/Inf ê°’ì„ ì•ˆì „í•œ ê°’ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
        def safe_float(value):
            if np.isnan(value) or np.isinf(value):
                return 0.0  # NaN/Infë¥¼ 0ìœ¼ë¡œ ëŒ€ì²´
            return float(value)
        
        def safe_complex_to_float(complex_val):
            real_part = safe_float(complex_val.real)
            imag_part = safe_float(complex_val.imag)
            return [real_part, imag_part]
        
        # ì•”í˜¸í™”ëœ ë°ì´í„°ë¥¼ JSONìœ¼ë¡œ ì§ë ¬í™” (ì•ˆì „í•œ ë³€í™˜)
        encrypted_data = {
            'client_id': CLIENT_ID,
            'round_id': r + 1,
            'c0_list': [[safe_complex_to_float(c) for c in c0] for c0 in c0_list],
            'c1_list': [[safe_complex_to_float(c) for c in c1] for c1 in c1_list],
            'original_size': len(flat),
            'num_samples': int(num_samples),
            'loss': safe_float(avg_loss),
            'accuracy': safe_float(accuracy)  # ë¼ìš´ë“œë³„ ì •í™•ë„ ì¶”ê°€
        }
        
        print(f"JSON ì§ë ¬í™” ë°ì´í„° í™•ì¸:", flush=True)
        print(f"  loss: {encrypted_data['loss']}", flush=True)
        print(f"  accuracy: {encrypted_data['accuracy']}", flush=True)
        print(f"  num_samples: {encrypted_data['num_samples']}", flush=True)
        print(f"  c0_list ê¸¸ì´: {len(encrypted_data['c0_list'])}", flush=True)
        print(f"  c1_list ê¸¸ì´: {len(encrypted_data['c1_list'])}", flush=True)
        
        try:
            print(f"ğŸ”„ ì„œë²„ë¡œ ë¼ìš´ë“œ {r+1} ë°ì´í„° ì „ì†¡ ì¤‘...", flush=True)
            response = requests.post(f"{SERVER_URL}/aggregate", json=encrypted_data, timeout=60)
            if response.status_code == 200:
                upload_end_time = time.time()
                upload_duration = upload_end_time - upload_start_time
                print(f"âœ… ì„œë²„ ì „ì†¡ ì™„ë£Œ (ì†Œìš”ì‹œê°„: {upload_duration:.2f}ì´ˆ)", flush=True)
                
                server_response = response.json()
                print(f"ğŸ“‹ ì„œë²„ ì‘ë‹µ: {server_response}", flush=True)
                
                # ì„œë²„ì—ì„œ ë‹¤ìŒ ë¼ìš´ë“œ ì§„í–‰ í—ˆìš© ì—¬ë¶€ í™•ì¸
                if server_response.get("status") == "success":
                    print(f"âœ… ë¼ìš´ë“œ {r+1} ì§‘ê³„ ì™„ë£Œ, ë‹¤ìŒ ë¼ìš´ë“œ ì§„í–‰ ê°€ëŠ¥", flush=True)
                else:
                    print(f"âš ï¸ ì„œë²„ ì§‘ê³„ ì¤‘ ë¬¸ì œ ë°œìƒ: {server_response.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}", flush=True)
                
                # ì ì‹œ ëŒ€ê¸° (ì„œë²„ ì²˜ë¦¬ ì‹œê°„ í™•ë³´)
                if r < NUM_ROUNDS - 1:  # ë§ˆì§€ë§‰ ë¼ìš´ë“œê°€ ì•„ë‹Œ ê²½ìš°
                    print(f"â³ ë‹¤ìŒ ë¼ìš´ë“œ ì¤€ë¹„ë¥¼ ìœ„í•´ 2ì´ˆ ëŒ€ê¸°...", flush=True)
                    time.sleep(2)
                    
            else:
                print(f"âŒ ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {response.status_code}", flush=True)
                print(f"ì‘ë‹µ ë‚´ìš©: {response.text}", flush=True)
        except Exception as e:
            print(f"âŒ ì„œë²„ í†µì‹  ì˜¤ë¥˜: {e}", flush=True)
            print("ë¡œì»¬ í•™ìŠµë§Œ ì§„í–‰í•©ë‹ˆë‹¤.", flush=True)
        
        round_end_time = time.time()
        round_duration = round_end_time - round_start_time
        print(f"\nğŸ === ë¼ìš´ë“œ {r+1}/{NUM_ROUNDS} ì™„ë£Œ (ì´ ì†Œìš”ì‹œê°„: {round_duration:.2f}ì´ˆ) ===", flush=True)
        print(f"ğŸ“Š ì„±ê³¼ ìš”ì•½:", flush=True)
        print(f"  ğŸ¯ í•™ìŠµ ì „ ì •í™•ë„: {acc_before:.2f}%", flush=True)
        print(f"  ğŸ¯ í•™ìŠµ í›„ ì •í™•ë„: {acc_after:.2f}%", flush=True)
        print(f"  ğŸ“‰ í‰ê·  ì†ì‹¤: {avg_loss:.4f}", flush=True)
        print(f"  ğŸ“ í•™ìŠµ ìƒ˜í”Œ ìˆ˜: {num_samples:,}", flush=True)
        print(f"â° ì™„ë£Œ ì‹œê°„: {time.strftime('%H:%M:%S')}", flush=True)
        
        if r < NUM_ROUNDS - 1:
            print(f"â³ ë‹¤ìŒ ë¼ìš´ë“œ ì¤€ë¹„ ì¤‘...", flush=True)
        print("=" * 60, flush=True)

    print("=== ëª¨ë“  ë¼ìš´ë“œ ì™„ë£Œ ===", flush=True)
    
    # ìµœì¢… ì˜ˆì¸¡ ìˆ˜í–‰
    print("=== ìµœì¢… ì˜ˆì¸¡ ìˆ˜í–‰ ===", flush=True)
    
    # ëª¨ë¸ í…ŒìŠ¤íŠ¸ (ë””ë²„ê¹…)
    print("=== ëª¨ë¸ í…ŒìŠ¤íŠ¸ ===")
    client_model.eval()
    with torch.no_grad():
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_input = torch.randn(5, input_dim).to(device)
        test_output = client_model(test_input)
        test_probs = torch.softmax(test_output, dim=1)
        print(f"í…ŒìŠ¤íŠ¸ ì…ë ¥ í˜•íƒœ: {test_input.shape}")
        print(f"í…ŒìŠ¤íŠ¸ ì¶œë ¥ í˜•íƒœ: {test_output.shape}")
        print(f"í…ŒìŠ¤íŠ¸ ì¶œë ¥ ìƒ˜í”Œ: {test_output[:3]}")
        print(f"í…ŒìŠ¤íŠ¸ í™•ë¥  ìƒ˜í”Œ: {test_probs[:3]}")
        print(f"í…ŒìŠ¤íŠ¸ í™•ë¥  í•©ê³„: {test_probs.sum(dim=1)[:3]}")
    
    try:
        # ì›ë³¸ ë°ì´í„° ë¡œë“œ (ì˜ˆì¸¡ìš©)
        if input_file and os.path.exists(input_file):
            # ì›ë³¸ ë°ì´í„°ë¥¼ ê·¸ëŒ€ë¡œ ë¡œë“œ (ì „ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ)
            original_df = pd.read_csv(input_file)
            print(f"ì›ë³¸ ë°ì´í„° ë¡œë“œ: {len(original_df)}í–‰, {len(original_df.columns)}ì—´")
        else:
            # ê¸°ë³¸ ë°ì´í„° íŒŒì¼ ì‚¬ìš©
            original_df = pd.read_csv('diabetic_data.csv')
            print(f"ê¸°ë³¸ ë°ì´í„° íŒŒì¼ ì‚¬ìš©: {len(original_df)}í–‰, {len(original_df.columns)}ì—´")
        
        # ì˜ˆì¸¡ìš© ë°ì´í„° ì „ì²˜ë¦¬ (í•™ìŠµê³¼ ë™ì¼í•œ íŠ¹ì„± ì‚¬ìš©)
        df_for_prediction = original_df.copy()
        drop_cols = ['encounter_id', 'patient_nbr']
        if all(col in df_for_prediction.columns for col in drop_cols):
            df_for_prediction = df_for_prediction.drop(columns=drop_cols)
        if 'readmitted' in df_for_prediction.columns:
            df_for_prediction['readmitted'] = df_for_prediction['readmitted'].map(lambda x: 0 if x == 'NO' else 1)
        
        # í•™ìŠµê³¼ ë™ì¼í•œ íŠ¹ì„± ì„ íƒ (8ê°œ ê³ ì • íŠ¹ì„±)
        fixed_features = [
            'admission_source_id', 'time_in_hospital', 'num_procedures', 
            'num_medications', 'number_outpatient', 'number_emergency', 
            'number_inpatient', 'number_diagnoses'
        ]
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ íŠ¹ì„±ë§Œ ì„ íƒ
        available_features = [col for col in fixed_features if col in df_for_prediction.columns]
        
        # ë¶€ì¡±í•œ ê²½ìš° ë‹¤ë¥¸ ìˆ«ìí˜• íŠ¹ì„± ì¶”ê°€
        if len(available_features) < 8:
            numeric_cols = df_for_prediction.select_dtypes(include=['int64', 'float64']).columns.tolist()
            numeric_cols = [col for col in numeric_cols if col != 'readmitted']
            remaining_cols = [col for col in numeric_cols if col not in available_features]
            available_features.extend(remaining_cols[:8-len(available_features)])
        
        # ì •í™•íˆ 8ê°œ íŠ¹ì„±ë§Œ ì‚¬ìš©
        selected_features_for_prediction = available_features[:8]
        
        # ì„ íƒëœ íŠ¹ì„±ìœ¼ë¡œ ë°ì´í„° ì¤€ë¹„
        X_pred = df_for_prediction[selected_features_for_prediction].values.astype('float32')
        print(f"ì˜ˆì¸¡ìš© ë°ì´í„° ì¤€ë¹„: {X_pred.shape}")
        print(f"ì˜ˆì¸¡ì— ì‚¬ìš©ë˜ëŠ” íŠ¹ì„±: {selected_features_for_prediction}")
        
        # ìŠ¤ì¼€ì¼ë§ ì ìš© (í•™ìŠµê³¼ ë™ì¼í•œ ë°©ì‹)
        from sklearn.preprocessing import StandardScaler
        scaler = StandardScaler()
        X_pred_scaled = scaler.fit_transform(X_pred)
        X_pred_scaled = np.nan_to_num(X_pred_scaled, nan=0.0, posinf=1.0, neginf=-1.0)
        
        print(f"ìŠ¤ì¼€ì¼ë§ í›„ ë°ì´í„° í˜•íƒœ: {X_pred_scaled.shape}")
        print(f"ìŠ¤ì¼€ì¼ë§ í›„ NaN ê°œìˆ˜: {np.isnan(X_pred_scaled).sum()}")
        
        # ì˜ˆì¸¡ ìˆ˜í–‰ (ìŠ¤ì¼€ì¼ë§ëœ ë°ì´í„° ì‚¬ìš©)
        probabilities, predictions, feature_importance = predict_diabetes_probability_with_explanation(client_model, 
            DataLoader(list(zip(X_pred_scaled, [0]*len(X_pred_scaled))), batch_size=64, shuffle=False), 
            selected_features_for_prediction, device)
        
        # ì›ë³¸ ë°ì´í„°ì— ì˜ˆì¸¡ ê²°ê³¼ ì¶”ê°€ (ì›ë³¸ í˜•ì‹ ìœ ì§€)
        result_df = original_df.copy()
        result_df['ë‹¹ë‡¨ë³‘_í™•ë¥ '] = probabilities
        result_df['ì˜ˆì¸¡_ê²°ê³¼'] = predictions
        result_df['ì˜ˆì¸¡_ë¼ë²¨'] = ['ë‹¹ë‡¨ë³‘' if p == 1 else 'ì •ìƒ' for p in predictions]
        
        # í™•ë¥ ë³„ë¡œ ì •ë ¬ (ì„ íƒì‚¬í•­)
        result_df = result_df.sort_values('ë‹¹ë‡¨ë³‘_í™•ë¥ ', ascending=False)
        
        success = save_results_to_excel(result_df, probabilities, predictions, feature_importance)
        
        if success:
            print("=== í•™ìŠµ ë° ì˜ˆì¸¡ ì™„ë£Œ ===", flush=True)
            print(f"ì´ {len(result_df)}ê°œ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ì™„ë£Œ", flush=True)
            print(f"ë‹¹ë‡¨ë³‘ ì˜ˆì¸¡: {sum(predictions)}ê°œ", flush=True)
            print(f"ì •ìƒ ì˜ˆì¸¡: {len(predictions) - sum(predictions)}ê°œ", flush=True)
            print(f"í‰ê·  ë‹¹ë‡¨ë³‘ í™•ë¥ : {np.mean(probabilities):.4f}", flush=True)
            return True
        else:
            print("ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨", flush=True)
            return False
            
    except Exception as e:
        print(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='FedHybrid í´ë¼ì´ì–¸íŠ¸')
    parser.add_argument('--input_file', type=str, help='ì…ë ¥ ë°ì´í„° íŒŒì¼ ê²½ë¡œ')
    args = parser.parse_args()
    
    success = main(args.input_file)
    sys.exit(0 if success else 1) 