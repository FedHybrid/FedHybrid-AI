#!/usr/bin/env python3
"""
ê°œì„ ëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import torch
import numpy as np
from improved_model import ImprovedEnhancerModel, load_improved_diabetes_data
from torch.utils.data import DataLoader

def test_model():
    """ëª¨ë¸ ê¸°ë³¸ ë™ì‘ í…ŒìŠ¤íŠ¸"""
    print("=== ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = torch.device('cpu')
    print(f"ë””ë°”ì´ìŠ¤: {device}")
    
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    input_dim = 8  # ê°œì„ ëœ ëª¨ë¸ì˜ íŠ¹ì„± ìˆ˜
    batch_size = 5
    num_classes = 2
    
    # ëª¨ë¸ ìƒì„±
    model = ImprovedEnhancerModel(input_dim=input_dim, num_classes=num_classes).to(device)
    print(f"ëª¨ë¸ ìƒì„± ì™„ë£Œ: {sum(p.numel() for p in model.parameters())}ê°œ íŒŒë¼ë¯¸í„°")
    
    # í…ŒìŠ¤íŠ¸ ì…ë ¥ ìƒì„± (ì •ê·œí™”ëœ ë°ì´í„°)
    test_input = torch.randn(batch_size, input_dim).to(device) * 0.5  # ì‘ì€ ê°’ìœ¼ë¡œ ì œí•œ
    print(f"í…ŒìŠ¤íŠ¸ ì…ë ¥ í˜•íƒœ: {test_input.shape}")
    print(f"ì…ë ¥ ë²”ìœ„: [{test_input.min().item():.4f}, {test_input.max().item():.4f}]")
    
    # ëª¨ë¸ ì‹¤í–‰
    model.eval()
    with torch.no_grad():
        output = model(test_input)
        probs = torch.softmax(output, dim=1)
        predictions = torch.argmax(output, dim=1)
    
    print(f"ì¶œë ¥ í˜•íƒœ: {output.shape}")
    print(f"ì¶œë ¥ ë²”ìœ„: [{output.min().item():.4f}, {output.max().item():.4f}]")
    print(f"í™•ë¥  í•©ê³„: {probs.sum(dim=1)}")
    print(f"ì˜ˆì¸¡: {predictions}")
    print(f"í™•ë¥ : {probs}")
    
    # NaN ì²´í¬
    if torch.isnan(output).any():
        print("âŒ ì¶œë ¥ì— NaN ê°ì§€!")
        return False
    else:
        print("âœ… ì¶œë ¥ì— NaN ì—†ìŒ")
    
    if torch.isinf(output).any():
        print("âŒ ì¶œë ¥ì— Inf ê°ì§€!")
        return False
    else:
        print("âœ… ì¶œë ¥ì— Inf ì—†ìŒ")
    
    print("=== ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„±ê³µ ===")
    return True

def test_data_loading():
    """ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸"""
    print("\n=== ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    try:
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
        import os
        test_files = ['diabetic_data.csv', 'diabetic.csv', 'test-data.csv']
        data_file = None
        
        for file in test_files:
            if os.path.exists(file):
                data_file = file
                break
        
        if data_file is None:
            print("í…ŒìŠ¤íŠ¸ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        print(f"ë°ì´í„° íŒŒì¼ ì‚¬ìš©: {data_file}")
        
        # ë°ì´í„° ë¡œë”©
        train_dataset, test_dataset, class_weights, selected_features = load_improved_diabetes_data(data_file)
        
        print(f"í•™ìŠµ ë°ì´í„°: {len(train_dataset)}ê°œ")
        print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_dataset)}ê°œ")
        print(f"ì„ íƒëœ íŠ¹ì„±: {selected_features}")
        print(f"í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜: {class_weights}")
        
        # ë°ì´í„° ë¡œë” ìƒì„±
        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
        
        # ì²« ë²ˆì§¸ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
        for x, y in train_loader:
            print(f"ë°°ì¹˜ í˜•íƒœ: X={x.shape}, y={y.shape}")
            print(f"X ë²”ìœ„: [{x.min().item():.4f}, {x.max().item():.4f}]")
            print(f"y ê°’: {y[:5]}")
            
            # NaN ì²´í¬
            if torch.isnan(x).any():
                print("âŒ ì…ë ¥ ë°ì´í„°ì— NaN ê°ì§€!")
                return False
            else:
                print("âœ… ì…ë ¥ ë°ì´í„°ì— NaN ì—†ìŒ")
            
            break  # ì²« ë²ˆì§¸ ë°°ì¹˜ë§Œ í…ŒìŠ¤íŠ¸
        
        print("=== ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ ì„±ê³µ ===")
        return True
        
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_training_step():
    """í•™ìŠµ ë‹¨ê³„ í…ŒìŠ¤íŠ¸"""
    print("\n=== í•™ìŠµ ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    try:
        # ëª¨ë¸ ìƒì„±
        device = torch.device('cpu')
        model = ImprovedEnhancerModel(input_dim=8, num_classes=2).to(device)
        
        # ë”ë¯¸ ë°ì´í„° ìƒì„±
        batch_size = 10
        x = torch.randn(batch_size, 8) * 0.5  # ì‘ì€ ê°’ìœ¼ë¡œ ì œí•œ
        y = torch.randint(0, 2, (batch_size,))
        
        # ì˜µí‹°ë§ˆì´ì € ë° ì†ì‹¤ í•¨ìˆ˜
        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
        criterion = torch.nn.CrossEntropyLoss()
        
        # í•™ìŠµ ë‹¨ê³„
        model.train()
        optimizer.zero_grad()
        
        output = model(x)
        loss = criterion(output, y)
        
        print(f"ì†ì‹¤: {loss.item():.4f}")
        
        if torch.isnan(loss) or torch.isinf(loss):
            print("âŒ ì†ì‹¤ì— NaN/Inf ê°ì§€!")
            return False
        
        loss.backward()
        
        # ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬
        total_grad_norm = 0
        for param in model.parameters():
            if param.grad is not None:
                if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():
                    print("âŒ ê·¸ë˜ë””ì–¸íŠ¸ì— NaN/Inf ê°ì§€!")
                    return False
                total_grad_norm += param.grad.data.norm(2).item() ** 2
        
        total_grad_norm = total_grad_norm ** 0.5
        print(f"ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„: {total_grad_norm:.4f}")
        
        optimizer.step()
        
        print("âœ… í•™ìŠµ ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì„±ê³µ")
        return True
        
    except Exception as e:
        print(f"âŒ í•™ìŠµ ë‹¨ê³„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

if __name__ == "__main__":
    print("ğŸ§ª FedHybrid-AI ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    success = True
    
    # 1. ëª¨ë¸ ê¸°ë³¸ ë™ì‘ í…ŒìŠ¤íŠ¸
    if not test_model():
        success = False
    
    # 2. ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸
    if not test_data_loading():
        success = False
    
    # 3. í•™ìŠµ ë‹¨ê³„ í…ŒìŠ¤íŠ¸
    if not test_training_step():
        success = False
    
    print("\n" + "=" * 50)
    if success:
        print("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        print("âŒ ì¼ë¶€ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨. ë¬¸ì œë¥¼ í•´ê²°í•´ì£¼ì„¸ìš”.")
    
    print("=" * 50)
