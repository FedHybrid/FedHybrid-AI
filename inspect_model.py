#!/usr/bin/env python3
"""
ì•”í˜¸í™”ëœ ëª¨ë¸ íŒŒì¼ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
"""

import torch
import numpy as np
import os
import sys

def analyze_encrypted_model(file_path):
    """ì•”í˜¸í™”ëœ ëª¨ë¸ íŒŒì¼ ë¶„ì„"""
    print(f"=== {file_path} íŒŒì¼ ë¶„ì„ ===")
    
    if not os.path.exists(file_path):
        print(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}")
        return
    
    try:
        # íŒŒì¼ ë¡œë“œ
        data = torch.load(file_path, map_location='cpu', weights_only=False)
        
        print(f"ğŸ“ íŒŒì¼ íƒ€ì…: {type(data)}")
        
        if isinstance(data, dict):
            print(f"ğŸ”‘ í‚¤ ëª©ë¡: {list(data.keys())}")
            
            # original_size í™•ì¸
            if 'original_size' in data:
                print(f"ğŸ“ ì›ë³¸ í¬ê¸°: {data['original_size']:,} íŒŒë¼ë¯¸í„°")
            
            # c0_list, c1_list í™•ì¸
            if 'c0_list' in data and 'c1_list' in data:
                c0_list = data['c0_list']
                c1_list = data['c1_list']
                
                print(f"ğŸ” c0_list ê¸¸ì´: {len(c0_list)} ë°°ì¹˜")
                print(f"ğŸ” c1_list ê¸¸ì´: {len(c1_list)} ë°°ì¹˜")
                
                if len(c0_list) > 0:
                    print(f"ğŸ“Š ì²« ë²ˆì§¸ ë°°ì¹˜ c0 í˜•íƒœ: {c0_list[0].shape}")
                    print(f"ğŸ“Š ì²« ë²ˆì§¸ ë°°ì¹˜ c1 í˜•íƒœ: {c1_list[0].shape}")
                    print(f"ğŸ“Š ì²« ë²ˆì§¸ ë°°ì¹˜ c0 ê°’: {c0_list[0]}")
                    print(f"ğŸ“Š ì²« ë²ˆì§¸ ë°°ì¹˜ c1 ê°’: {c1_list[0]}")
                    
                    # ê°’ ë²”ìœ„ í™•ì¸
                    c0_values = np.concatenate([c0.flatten() for c0 in c0_list])
                    c1_values = np.concatenate([c1.flatten() for c1 in c1_list])
                    
                    print(f"ğŸ“ˆ c0 ì „ì²´ ê°’ ë²”ìœ„: {c0_values.real.min():.3f} ~ {c0_values.real.max():.3f}")
                    print(f"ğŸ“ˆ c1 ì „ì²´ ê°’ ë²”ìœ„: {c1_values.real.min():.3f} ~ {c1_values.real.max():.3f}")
                    print(f"ğŸ“ˆ c0 í‰ê· : {c0_values.real.mean():.3f}")
                    print(f"ğŸ“ˆ c1 í‰ê· : {c1_values.real.mean():.3f}")
        
        elif isinstance(data, torch.nn.Module):
            print("ğŸ§  ì¼ë°˜ PyTorch ëª¨ë¸ì…ë‹ˆë‹¤")
            print(f"ğŸ“Š ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {sum(p.numel() for p in data.parameters()):,}")
            
        else:
            print(f"â“ ì•Œ ìˆ˜ ì—†ëŠ” ë°ì´í„° íƒ€ì…: {type(data)}")
            
    except Exception as e:
        print(f"âŒ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    if len(sys.argv) > 1:
        file_path = sys.argv[1]
    else:
        file_path = "encrypted_global_model.pth"
    
    analyze_encrypted_model(file_path)
    
    # ë‹¤ë¥¸ ëª¨ë¸ íŒŒì¼ë“¤ë„ í™•ì¸
    model_files = [
        "global_model.pth",
        "encrypted_global_model.pth"
    ]
    
    print("\n" + "="*50)
    print("ğŸ“‚ í˜„ì¬ ë””ë ‰í† ë¦¬ì˜ ëª¨ë¸ íŒŒì¼ë“¤:")
    
    for file in model_files:
        if os.path.exists(file):
            file_size = os.path.getsize(file) / (1024 * 1024)  # MB
            print(f"ğŸ“„ {file} ({file_size:.2f} MB)")
        else:
            print(f"âŒ {file} (ì¡´ì¬í•˜ì§€ ì•ŠìŒ)")

if __name__ == "__main__":
    main() 